---
title: Home
feature_image: "https://images.unsplash.com/photo-1591805058622-5ef21ba2fdf5?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=654&q=80"
feature_text: |
 ## Yvette's Website
layout: categories
excerpt: "Category index"
aside: true
---

<!-- https://picsum.photos/1300/400?image=989 -->

<!-- ### Table of contents
>   1. [學歷](#education)
>   2. [經歷](#experience)
>   3. [證照](#licenses&certifications)
>   4. [技能](#skills)
>   5. [出版](#publications)
>   6. [專案](#projects) -->

[學歷](#education) | [經歷](#experience) | [證照](#licenses&certifications) | [技能](#skills) | [出版](#publications) | [專案](#projects)

---

### 學歷 <a name="education"></a>      
**國立臺北大學**   
碩士, 資訊管理研究所   
Sep 2021 - Jun 2023

**臺北醫學大學**   
學士, 食品安全學系  
Sep 2017 - Jun 2021

### 經歷 <a name="experience"></a>     
**實習生**   
DeepWave · 實習生   
Jul 2022 - Present   
台灣 台北市大安區   
公司網站：[https://dwave.cc/](https://dwave.cc/) 

**研究助理**   
國立臺北大學   
Aug 2021 - Present   
台灣 新北市三峽區    

**暑期實習生**   
新北市政府衛生局 · 實習生   
Jul 2020 - Aug 2020   
台灣 新北市板橋區   
實習單位：食品藥物管理科   

### 證照 <a name="licenses&certifications"></a>     
**Amazon Web Services Cloud Practitioner**   
Issued Feb 2022 · Expires Feb 2025   

### 技能 <a name="skills"></a>   
雲端運算 Cloud Computing  
雲端平台 Amazon Web Services (AWS)    
機器學習 Machine Learning    
自然語言處理 Natural Language Processing (NLP)   
資料科學 Data Science   
容器 Docker    
Python    
MySQL    
敏捷開發 Scrum

### 出版 <a name="publications"></a>   
**IMNTPU at the NTCIR-16 FinNum-3 Task: <a name="FinNum3"></a>   
Data Augmentation for Financial Numclaim Classification**   
NTCIR 16 Conference · Jun 14, 2022   
**Abstract**: This paper provides a detailed description of IMNTPU team at the NTCIR-16 FinNum-3 shared task in formal financial documents. We proposed the use of the XLM-RoBERTa-based model with two different approaches on data augmentation to perform the binary classification task in FinNum-3. The first run (i.e., IMNTPU-1) is our baseline through the fine-tuning of the XLM-RoBERTa without data augmentation. However, we assume that presenting different data augmentations may improve the task performance because of the imbalance in the dataset. Accordingly, we presented double redaction and translation methods on data augmentation in the second (IMNTPU-2) and third (IMNTPU-3) runs, respectively. The best macro-F1 scores obtained by our team in the Chinese and English datasets are 93.18% and 89.86%, respectively. The major contribution of this study provides a new understanding of data augmentation approach for the imbalanced dataset, which may help reduce the imbalanced situation in the Chinese and English datasets.   
<img src="https://user-images.githubusercontent.com/82231499/173595390-937d8a24-0c1a-4865-a78b-171547e8ea7f.png" width="15" height="15"> 
<!-- [[Pdf]](https://research.nii.ac.jp/ntcir/workshop/OnlineProceedings16/pdf/ntcir/08-NTCIR16-FINNUM-TengY.pdf)[[Poster]]() -->
<a href="https://research.nii.ac.jp/ntcir/workshop/OnlineProceedings16/pdf/ntcir/08-NTCIR16-FINNUM-TengY.pdf" target="_blank">[Pdf]</a>
<a href="" target="_blank">[Poster]</a>   

### 專案 <a name="projects"></a>   
**競賽 | NTCIR-16 FinNum-3**   
Dec 2021 - Jun 2022   
此競賽針對專業財務文件 (法說會或財務分析書) 中的數字進行細粒度分析，並利用二元分類細分出句子中的數字是否為專家對於專業財務文件分析出的數字，並用 Macro F1-score 來評估模型績效。並於中文及英文資料集分別得到第一 (93.18%) 及第三名 (89.86%)。此外，亦於 NTCIR-16 Conference 發表了研討會論文，題目為：[IMNTPU at the NTCIR-16 FinNum-3 Task: Data Augmentation for Financial Numclaim Classification](#FinNum3).
